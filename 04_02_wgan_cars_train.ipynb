{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfoster/.virtualenvs/gdl/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.WGAN import WGAN\n",
    "from utils.loaders import load_cifar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0002'\n",
    "DATA_NAME = 'horses'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_NAME == 'cars':\n",
    "    label = 1\n",
    "elif DATA_NAME == 'horses':\n",
    "    label = 7\n",
    "(x_train, y_train) = load_cifar(label, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a5d8160>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((x_train[150,:,:,:]+1)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if mode == 'build':\n",
    "\n",
    "    gan = WGAN(input_dim = (32,32,3)\n",
    "            , critic_conv_filters = [32,64,128,128]\n",
    "            , critic_conv_kernel_size = [5,5,5,5]\n",
    "            , critic_conv_strides = [2,2,2,1]\n",
    "            , critic_batch_norm_momentum = None\n",
    "            , critic_activation = 'leaky_relu'\n",
    "            , critic_dropout_rate = None\n",
    "            , critic_learning_rate = 0.00005\n",
    "            , generator_initial_dense_layer_size = (4, 4, 128)\n",
    "            , generator_upsample = [2,2, 2,1]\n",
    "            , generator_conv_filters = [128,64,32,3]\n",
    "            , generator_conv_kernel_size = [5,5,5,5]\n",
    "            , generator_conv_strides = [1,1, 1,1]\n",
    "            , generator_batch_norm_momentum = 0.8\n",
    "            , generator_activation = 'leaky_relu'\n",
    "            , generator_dropout_rate = None\n",
    "            , generator_learning_rate = 0.00005\n",
    "            , optimiser = 'rmsprop'\n",
    "            , z_dim = 100\n",
    "            )\n",
    "    gan.save(RUN_FOLDER)\n",
    "\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_input (InputLayer)    (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "critic_conv_0 (Conv2D)       (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "critic_conv_1 (Conv2D)       (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "critic_conv_2 (Conv2D)       (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "critic_conv_3 (Conv2D)       (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 670,401\n",
      "Trainable params: 670,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              206848    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2D)    (None, 8, 8, 128)         409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2D)    (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2D)    (None, 32, 32, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 32, 32, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 884,163\n",
      "Trainable params: 879,619\n",
      "Non-trainable params: 4,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 6000\n",
    "PRINT_EVERY_N_BATCHES = 5\n",
    "N_CRITIC = 5\n",
    "CLIP_THRESHOLD = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfoster/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: (-0.000)(R -0.001, F 0.000)]  [G loss: -0.000] \n",
      "1 [D loss: (-0.000)(R -0.001, F 0.001)]  [G loss: -0.000] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c358e4712d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPRINT_EVERY_N_BATCHES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mn_critic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN_CRITIC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m,\u001b[0m \u001b[0mclip_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIP_THRESHOLD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/Git/Personal/GDL/GDL_code/models/WGAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, n_critic, clip_threshold, using_generator)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_critic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                 \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/Personal/GDL/GDL_code/models/WGAN.py\u001b[0m in \u001b[0;36mtrain_critic\u001b[0;34m(self, x_train, batch_size, clip_threshold, using_generator)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , n_critic = N_CRITIC\n",
    "    , clip_threshold = CLIP_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.sample_images(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot(gan.g_losses, color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "# plt.xlim(0, 2000)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(img1, img2):\n",
    "    return np.mean(np.abs(img1 - img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r, c = 5, 5\n",
    "\n",
    "idx = np.random.randint(0, x_train.shape[0], BATCH_SIZE)\n",
    "true_imgs = (x_train[idx] + 1) *0.5\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(true_imgs[cnt], cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/real.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 5, 5\n",
    "noise = np.random.normal(0, 1, (r * c, gan.z_dim))\n",
    "gen_imgs = gan.generator.predict(noise)\n",
    "\n",
    "#Rescale images 0 - 1\n",
    "\n",
    "gen_imgs = 0.5 * (gen_imgs + 1)\n",
    "# gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]), cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample.png\"))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        c_diff = 99999\n",
    "        c_img = None\n",
    "        for k_idx, k in enumerate((x_train + 1) * 0.5):\n",
    "            \n",
    "            diff = compare_images(gen_imgs[cnt, :,:,:], k)\n",
    "            if diff < c_diff:\n",
    "                c_img = np.copy(k)\n",
    "                c_diff = diff\n",
    "        axs[i,j].imshow(c_img, cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample_closest.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdl",
   "language": "python",
   "name": "gdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
