{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfoster/.virtualenvs/gdl/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.GAN import GAN\n",
    "from utils.loaders import load_safari\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'camel'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) = load_safari(DATA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x149b18ef0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[200,:,:,0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'build':\n",
    "\n",
    "    gan = GAN(input_dim = (28,28,1)\n",
    "            , discriminator_conv_filters = [64,64,128,128]\n",
    "            , discriminator_conv_kernel_size = [5,5,5,5]\n",
    "            , discriminator_conv_strides = [2,2,2,1]\n",
    "            , discriminator_batch_norm_momentum = None\n",
    "            , discriminator_activation = 'relu'\n",
    "            , discriminator_dropout_rate = 0.4\n",
    "            , discriminator_learning_rate = 0.0008\n",
    "            , generator_initial_dense_layer_size = (7, 7, 64)\n",
    "            , generator_upsample = [2,2, 1, 1]\n",
    "            , generator_conv_filters = [128,64, 64,1]\n",
    "            , generator_conv_kernel_size = [5,5,5,5]\n",
    "            , generator_conv_strides = [1,1, 1, 1]\n",
    "            , generator_batch_norm_momentum = 0.9\n",
    "            , generator_activation = 'relu'\n",
    "            , generator_dropout_rate = None\n",
    "            , generator_learning_rate = 0.0004\n",
    "            , optimiser = 'rmsprop'\n",
    "            , z_dim = 100\n",
    "            )\n",
    "\n",
    "    gan.save(RUN_FOLDER)\n",
    "\n",
    "else:\n",
    "    GAN.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_0 (Conv2D (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_1 (Conv2D (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_2 (Conv2D (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_3 (Conv2D (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 720,833\n",
      "Trainable params: 720,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2D)    (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2D)    (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2DTran (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 28, 28, 1)         1601      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 844,161\n",
      "Trainable params: 837,377\n",
      "Non-trainable params: 6,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 6000\n",
    "PRINT_EVERY_N_BATCHES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfoster/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: (0.727)(R 0.691, F 0.763)] [D acc: (0.320)(0.641, 0.000)] [G loss: 0.678] [G acc: 1.000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cef2b0cd8bca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPRINT_EVERY_N_BATCHES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/Git/Personal/GDL/GDL_code/models/GAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, using_generator)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/Personal/GDL/GDL_code/models/GAN.py\u001b[0m in \u001b[0;36mtrain_generator\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[3] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "plt.plot([x[4] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[5] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[1] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('accuracy', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdl",
   "language": "python",
   "name": "gdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
